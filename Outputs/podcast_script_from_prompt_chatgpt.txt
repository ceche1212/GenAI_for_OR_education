Speaker,Text
Speaker A,"Welcome to the show. Today we’re unpacking the world of order batching in warehouses, a topic that sounds niche, but quietly powers your next-day deliveries."
Speaker B,"Absolutely. If you’ve ever clicked “Buy Now” and wondered how a warehouse grabs all those items so fast, order batching is a big part of the answer. Think of it as carpooling for orders. 
"
Speaker A,"Nice analogy. Instead of sending a picker to fetch one customer’s order at a time, the system groups several orders into a batch and collects all their items on a single route. That’s the core idea. 
"
Speaker B,"And the review we’re drawing on focuses on the most common setup you’ll see in the research world, which is a manual, picker-to-parts warehouse with a rectangular layout, parallel aisles, and one or two cross aisles. Routes start and end at a “depot.” 
"
Speaker A,"Picture a supermarket at closing time. Shelves form those long parallel aisles. A worker starts at the front corner, snakes through the aisles, then returns to the checkout area. That’s your depot. 
"
Speaker B,"Order batching is more than a single trick, though. Once you decide to batch, a cascade of other decisions appears: how long to wait before starting, which batch to pick next, who picks it, what route to follow, and how to sort items back to individual orders. 
"
Speaker A,"Let’s set up the conversation. We’ll first define the key tasks, then the goals we optimize for, then the taxonomy that researchers use to classify problems, and finally some state-of-the-art insights and open questions. Sound good?"
Speaker B,"Perfect. Let’s start with those tasks, because they show how batching ripples through the whole operation. 
"
Speaker A,"Task one is waiting. A picker may pause before starting a new route. The longer you wait, the more orders accumulate, and the better a batch you can build—up to a point. It’s like waiting a few minutes for ride-share pool to pick up more passengers. 
"
Speaker B,"Task two is selecting or sequencing. If you choose just the next batch, that’s selecting. If you prioritize the entire queue of batches, that’s sequencing—basically making a playlist of work. 
"
Speaker A,"Task three is assigning. In multi-picker environments, you decide which person gets which batch, with an eye on balancing workload. Think of a kitchen pass deciding which chef takes the next ticket. 
"
Speaker B,"Task four is routing. That’s the literal path a picker takes through the warehouse. We care because the route determines distance and time. Different route heuristics—like the classic S-shape—can change performance a lot. 
"
Speaker A,"And task five is sorting. If you batch pick different customers’ items into one cart, you still need to split them back into individual orders, either during the pick if your cart has separate bins, or afterward at a sorting area. 
"
Speaker B,"One big payoff from batching is less travel. In fact, when routes are designed with batching in mind, travel time can drop by as much as about 35 percent compared with strict single-order picking. That’s a huge lever. 
"
Speaker A,"But batching isn’t always right. It’s especially powerful in business-to-consumer scenarios with many small items. In some business-to-business settings, where you move whole pallets, single-order picking can still make sense. 
"
Speaker B,"Okay, now the goals, or objective functions. The review groups the common targets as time, distance, cost, tardiness or earliness against due dates, completion time across all orders, turnover time per order, workload balance among pickers, and even blocking or congestion in aisles. 
"
Speaker A,"A quick translation. Distance is just meters walked. Time includes walking and handling. Cost is the money proxy for all this. Tardiness means how late you are versus a due date. Earliness is being too early, which can be bad if it clogs staging areas. 
"
Speaker B,"Two special time-based measures crop up in online settings where orders arrive dynamically. Completion time is how long to finish all orders in the system, and turnover time is how long each order spends from arrival to completion. 
"
Speaker A,"Also, in multi-picker worlds, you care about fairness: workload balance. You don’t want one picker sprinting marathons while another strolls. And then there’s blocking time, which is waiting because an aisle or the depot is occupied. That’s congestion. 
"
Speaker B,"There’s a neat equivalence worth noting. If walking speed is basically constant, then minimizing distance and minimizing travel time are effectively the same objective. That helps simplify models. 
"
Speaker A,"Now the taxonomy—the map that helps us label each flavor of problem. The review breaks it into three parts: constraints, objective functions, and decision variables. Let’s decode that. 
"
Speaker B,"For constraints, there are two big axes. First, offline versus online. Offline means you’ve got all the orders known before you start. Online means orders arrive dynamically, so you’re planning while the stream keeps coming. 
"
Speaker A,"Second, single picker versus multiple pickers. With one picker, there’s no aisle blocking and you just sequence batches one after another. With multiple pickers, blocking can occur and you need assignment and balancing decisions. 
"
Speaker B,"On objectives, we just covered the menu. On variables, the taxonomy lists five task buckets you might optimize: batching, sequencing, assigning, routing, and waiting. A specific study chooses some subset, maybe one task or several together. 
"
Speaker A,"And here’s a handy tag format the paper suggests. You write a code like OFF-SP-TA-B, which means “offline, single picker, minimize tardiness, and we optimize batching.” It’s like a license plate for your setup. 
"
Speaker B,"Big picture, offline is a special case of online, and single-picker is a special case of multi-picker. So when you solve the more general versions, you cover the simpler ones too. 
"
Speaker A,"Let’s tour the main problem families using that map. We’ll start with the offline single-picker world. These are classic testbeds in the literature."
Speaker B,"The simplest is OBP, the Order Batching Problem. You only optimize batching, usually to reduce distance or picking time, sometimes cost. Routing is often computed with a standard heuristic like S-shape while the batching algorithm does the heavy lifting. 
"
Speaker A,"Step up to OBSP, where you batch and sequence. Here, due dates matter more, so tardiness and sometimes earliness enter the picture. Common sense rules like Earliest Due Date often seed solutions and then metaheuristics refine them. 
"
Speaker B,"Then there’s OBRP, batching plus routing. Now you’re co-designing “who’s together” and “how to walk it,” which often yields big gains because the best batches depend on the route and vice versa. 
"
Speaker A,"And the triathlon, OBSRP, where batching, sequencing, and routing are optimized together, often targeting tardiness or cost. This mirrors what real supervisors do—make tradeoffs between who to serve next and how to get there. 
"
Speaker B,"Switching to offline multiple-picker settings, you see the same families but with added complexity. Blocking can arise when two pickers collide or queue at the depot, and you must assign batches across people while balancing workload. 
"
Speaker A,"One flavor is OBPMP, where you still “just” batch, but multiple pickers execute those batches. Others add sequencing, assigning, or routing alongside batching—OBSPMP, OBAPMP, OBRPMP, and more. Think of a dispatcher allocating delivery routes to several drivers in a tight grid. 
"
Speaker B,"Now for the online world, which is closer to how e-commerce really runs. Orders arrive continuously. You can’t wait forever, but you also don’t want to run half-empty batches."
Speaker A,"Online single-picker problems include OOBP and OOBWP, the latter explicitly adding waiting as a decision. Research there experiments with no-wait, fixed time windows, or variable time windows that flex when order inflow changes. 
"
Speaker B,"There are also online versions that combine batching with routing, and even batching plus routing plus sequencing—because when orders keep coming, deciding the next best action becomes a rolling puzzle. 
"
Speaker A,"Finally, the online multiple-picker frontier. Here you might optimize batching, sequencing, assigning, and routing together while the order stream flows. Imagine air-traffic control, but for pickers and carts. The taxonomy even gives this a mouthful of a label like OOBSARPMP. 
"
Speaker B,"Let’s connect this to the warehouse floor. Suppose we’re running a rectangular warehouse with a single front depot. On Monday morning, orders spike. A smart policy might widen the batching time window to capture more orders per batch, then shrink it near cutoff times to hit due dates. The literature treats that as explicitly optimizing the waiting task. 
"
Speaker A,"On routing, the S-shape heuristic is a workhorse. It’s simple and widely used across studies. But as batches change and aisles get busy, you might switch to more adaptive routing or even exact algorithms when feasible. The point is, batching and routing go hand in hand. 
"
Speaker B,"Another real-world detail is sorting. If you pick-to-cart with bins, you can “sort while pick.” If not, you “pick then sort” at a station. That choice affects cart capacity and batch composition constraints, which loops back into batching decisions. 
"
Speaker A,"Speaking of capacity, batches are limited by things like cart weight, volume, number of items, or even number of orders. Those caps shape what “good” batching looks like for your facility. 
"
Speaker B,"Let’s pepper in a few headline findings from the review. First, batching can substantially cut travel—again, up to about a third when routes are co-designed—so it’s worth the effort to integrate these decisions. 
"
Speaker A,"Second, the literature has focused more on offline than online variants, and more on single-picker than multi-picker. The authors counted 36 taxonomy variants and found half had never been tackled, with the heaviest attention on offline, single-picker batching alone. 
"
Speaker B,"To put numbers on it, roughly 47 percent of papers are offline single-picker, 27 percent offline multi-picker, and about 13 percent each for the two online categories. The single most studied variant is offline OBP with a single picker. 
"
Speaker A,"Third, everyone models routing and batching somehow, but far fewer papers optimize sequencing, fewer still assignment, and only a handful treat waiting as a first-class decision—even though waiting strongly influences performance in online settings. 
"
Speaker B,"That leads to the authors’ big recommendation. Move from the tidy, theoretical cases to more realistic ones—online arrivals with multiple pickers—and study joint decision making across batching, sequencing, assigning, routing, and waiting. 
"
Speaker A,"They also argue that offline and single-picker are special cases of online and multi-picker, so if you solve the general case well, you inherit solutions to the simpler ones. That’s efficient science. 
"
Speaker B,"Let’s ground this with a small scenario. Imagine three incoming orders in the next five minutes. One is due in an hour, two have flexible deadlines. A no-wait policy might leave with just the first order and wander a long path. A variable time window waits a couple of minutes, adds the second order, and picks a tighter route. You hit the due date and walk less. That’s the waiting knob at work. 
"
Speaker A,"Another scenario. Two pickers in adjacent aisles both need the same cross aisle. Without coordination, one blocks the other. Your objective might penalize blocking time, and your assigning policy might stagger batches so they don’t collide. That’s where multi-picker models shine. 
"
Speaker B,"And if your business has a daily wave—say, 8 p.m. order bursts—you might sequence batches to cover urgent orders first, then fill gaps with non-urgent ones, balancing tardiness against travel. That’s the OBSP mindset brought to life. 
"
Speaker A,"A quick note on objectives and tradeoffs. If you chase pure distance, you might clump items that are spatially close but deliver some orders too early or too late. If you prize due-date performance, you might accept longer paths. Multi-objective thinking or cost functions that blend these elements help reflect reality. 
"
Speaker B,"And remember, time and distance often travel together. If walking speed is stable, saving meters usually saves minutes. That lets you compare methods more cleanly and reuse routing insights across time-based and distance-based models. 
"
Speaker A,"Zooming out, the taxonomy itself is a powerful communication tool. It lets engineers, data scientists, and managers say exactly which variant they’re tackling, and see what the literature says about it. That avoids apples-to-oranges comparisons. 
"
Speaker B,"For example, if someone says, “We solved OFF-SP-TA-B,” you know it’s offline, single picker, minimizing tardiness, optimizing batching. If your world is online with multiple pickers, you’ll instantly know that method needs adaptation. 
"
Speaker A,"Let’s also flag warehouse geometry. Most studies use the single-block rectangular layout with a single depot, but there are variations—multiple blocks, irregular shapes, multiple depots, even storage at different heights. Your layout matters for routing and batching payoffs. 
"
Speaker B,"Which brings us to practical advice. If you’re starting from strict order picking, begin with simple batching and a standard route heuristic. Measure distance and time changes. Then iterate—add sequencing for due dates, introduce basic assignment rules if you have multiple pickers, and experiment with a small waiting window during peak inflow. 
"
Speaker A,"And adopt the taxonomy mindset from day one. It keeps teams aligned on what problem you’re actually solving, which objectives you’re optimizing, and which tasks you’ve modeled. That clarity pays off in both engineering and stakeholder conversations. 
"
Speaker B,"Before we wrap, let’s recap the big takeaways. One, order batching groups orders so items are picked together on one route, which can significantly cut travel when routes are co-designed. 
"
Speaker A,"Two, batching touches many interconnected tasks—waiting, selecting or sequencing, assigning, routing, and sorting—and each adds decisions and constraints that shape performance. 
"
Speaker B,"Three, objectives span time, distance, cost, due-date performance, system-level times like completion and turnover, fairness across pickers, and congestion. Choose the ones that reflect your business reality. 
"
Speaker A,"Four, use the taxonomy to label your variant clearly, and remember that solving online multi-picker problems can generalize to offline or single-picker cases. 
"
Speaker B,"Five, the field is ripe for progress in realistic, joint decision models, especially those that include waiting and assignment in dynamic settings. If you’re researching or building systems, that’s fertile ground. 
"
Speaker A,"Alright, that’s our tour through order batching. We hope this helped demystify the jargon and connect it to everyday operations."
Speaker B,"If you enjoyed this deep dive, share it with a colleague who geeks out about operations. Thanks for listening, and see you next time."